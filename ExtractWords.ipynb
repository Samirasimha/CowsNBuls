{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a821dc97-3411-4af6-8a94-b239eb62cf29",
   "metadata": {},
   "source": [
    "# Cows and Bulls Words Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cbf636-3031-43fd-9a70-e43830104532",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eef9146-a1f3-488b-95c4-fd397bf256c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "extraction_path = './temp'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72561c2b-4ced-4783-b629-e13559ba8a7b",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b8d87c-cda2-4370-823c-7d6bb4473901",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checks if the character has any characters that are repeated. \n",
    "def all_unique_characters(word):\n",
    "    return len(set(word)) == len(word)\n",
    "\n",
    "# takes a df and returns only the words that are of 4 characters long and the ones that do not have any charaters repeated. \n",
    "def filter_4_letter_words_and_unique(item,field_name):\n",
    "    return item[item[field_name].apply(lambda x: len(x) == 4 and all_unique_characters(x))]\n",
    "\n",
    "# returns list of words that are repeated more than n times in the df\n",
    "def fitler_words_repeated_more_than_n_times(item,field_name,n):\n",
    "    return item[item[field_name] > n]\n",
    "\n",
    "# set Subtraction \n",
    "def subtract(left,right,left_field,right_field):\n",
    "    merged_df = left.merge(right, how='left', left_on='Word', right_on='Name', indicator=True)\n",
    "    filtered_df = merged_df[merged_df['_merge'] == 'left_only']\n",
    "    return filtered_df\n",
    "\n",
    "# Get the top n words that are of 4 characters in length\n",
    "def get_top_4_letter_words(file_path, top_n=1500):\n",
    "    # Read the content of the file\n",
    "    with open(file_path, 'r', encoding='latin-1') as file:\n",
    "        text = file.read().lower()\n",
    "    \n",
    "    # Tokenize the text and filter out non-4-letter words with no numbers or special characters\n",
    "    words = re.findall(r'\\b[a-z]{4}\\b', text)\n",
    "    \n",
    "    # Count the frequency of each 4-letter word\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Get the most common 4-letter words\n",
    "    most_common_words = word_counts.most_common(top_n)\n",
    "    \n",
    "    return most_common_words\n",
    "\n",
    "# Function to process all text files in a folder\n",
    "def process_folder(folder_path):\n",
    "    all_words = []\n",
    "    complete_text = \"\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "                            \n",
    "            top_4_letter_words = get_top_4_letter_words(file_path)\n",
    "            all_words.append(top_4_letter_words)\n",
    "    return all_words\n",
    "\n",
    "#Calculates the average repetition of a word across multiple files. \n",
    "def calculate_average_frequency(lists):\n",
    "    frequency_dict = {}\n",
    "\n",
    "    # Iterate over each list and update the dictionary\n",
    "    for lst in lists:\n",
    "        for name, frequency in lst:\n",
    "            if name in frequency_dict:\n",
    "                frequency_dict[name]['total'] += frequency\n",
    "            else:\n",
    "                frequency_dict[name] = {'total': frequency}\n",
    "\n",
    "    # Calculate the average frequency for each name\n",
    "    average_frequency_list = [\n",
    "        (name, values['total'] / len(lists))\n",
    "        for name, values in frequency_dict.items()\n",
    "    ]\n",
    "\n",
    "    return average_frequency_list\n",
    "\n",
    "#UnZip a file and save it\n",
    "\n",
    "def unzip_file(zip_file_path, file_extension):\n",
    "    # Check if the zip file exists\n",
    "    if not os.path.isfile(zip_file_path):\n",
    "        print(f\"Error: The zip file {zip_file_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(extraction_path, exist_ok=True)\n",
    "\n",
    "    # Open the zip file\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # List all the files in the zip archive\n",
    "        zip_file_list = zip_ref.namelist()\n",
    "        \n",
    "        # Filter for files with specified extension\n",
    "        files_with_extension = [f for f in zip_file_list if f.endswith(file_extension)]\n",
    "\n",
    "        if not files_with_extension:\n",
    "            print(f\"No files with '{file_extension}' extension found in the zip archive.\")\n",
    "        else:\n",
    "            # Extract and process each file with the specified extension\n",
    "            for file_name in files_with_extension:\n",
    "                try:\n",
    "                    # Ensure subdirectories are correctly handled\n",
    "                    base_name = os.path.basename(file_name)\n",
    "                    extracted_file_path = os.path.join(extraction_path, base_name)\n",
    "                \n",
    "                    # Extract the file to the specified path\n",
    "                    with zip_ref.open(file_name) as source, open(extracted_file_path, 'wb') as target:\n",
    "                        target.write(source.read())\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing {file_name}: {e}\")\n",
    "\n",
    "def delete_folder():\n",
    "    shutil.rmtree(extraction_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271515f-3035-483b-a253-546ecfff17b9",
   "metadata": {},
   "source": [
    "## Extract 4 Letter Names without repeated Characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391d8636-bce4-4021-91f3-0ea9048e128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "unzip_file('Names/Names.csv.zip','.csv')\n",
    "names_df = pd.read_csv(extraction_path+'/Names.csv')\n",
    "# Filter names that are 4 characters long\n",
    "names_df['Name'] = names_df['Name'].astype(str)  # Ensure 'Name' column is string type\n",
    "\n",
    "names_df['Name'] = names_df['Name'].str.lower()\n",
    "\n",
    "# Filter names that do not have repeating characters\n",
    "names_no_repeats = filter_4_letter_words_and_unique(names_df,'Name')\n",
    "\n",
    "names_no_repeats = names_no_repeats.drop_duplicates(subset='Name')\n",
    "delete_folder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bf631e-4d07-4e98-b543-7b036f292476",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_file('Books/Books.zip','.txt')\n",
    "folder_path = extraction_path \n",
    "each_books_top_n_words = calculate_average_frequency(process_folder(folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa77b9e-4a28-4a9d-879a-8dbb9aec0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_books_top_n_words = pd.DataFrame(each_books_top_n_words, columns=['Word', 'Frequency'])\n",
    "\n",
    "average_4_letter_words = filter_4_letter_words_and_unique(each_books_top_n_words,'Word')\n",
    "\n",
    "average_4_letter_words = average_4_letter_words.drop_duplicates(subset='Word')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfaeaca-fcb4-430c-aa05-9f95d8fd2968",
   "metadata": {},
   "source": [
    "## Let's remove all the words that are names of People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19a2b2a-9447-43f9-b927-3713c058335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_without_human_names = subtract(average_4_letter_words,names_no_repeats,'Word','Name')\n",
    "words_without_human_names = words_without_human_names[['Word','Frequency']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f677cb-6c8a-46d9-b038-007d788a8bdd",
   "metadata": {},
   "source": [
    "## Let's store the top 1000 most frequently used words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815fb377-e98e-476d-a90c-c228a866f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_without_human_names = words_without_human_names.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "top_1000 = words_without_human_names.head(1000)\n",
    "\n",
    "top_1000.to_csv('result.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e479c59b-359a-4c85-a64d-acd46e130214",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f5415-676c-4675-8f64-b59fd6ca66ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
